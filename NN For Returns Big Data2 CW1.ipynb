{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN39/NXfxujICOl0/iN9B+Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indipanesar96/neural-style-tf/blob/master/NN%20For%20Returns%20Big%20Data2%20CW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwDO8B9qvPdl",
        "colab_type": "code",
        "outputId": "0ae6a2d0-ba37-4518-c112-6bf50f76a8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#code32and18.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf # to create neural networks\n",
        "import numpy as np # to manipulate arrays\n",
        "import matplotlib.pyplot as plt # for plots\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import he_normal\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8pOq59Gv2wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is just to allow colab to read the file, when we submit we wont need this\n",
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# The shared link for the csv file\n",
        "link = 'https://drive.google.com/open?id=1_5T1cpgLHuo6tQYhW4oi4zJ_bYKCjGq5'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('CPZ_data_mini.csv')  \n",
        "df = pd.read_csv('CPZ_data_mini.csv') #this is the only line we need from this block when submitting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNi3NumYvU7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "df.sort_values(by=['permno','Date'],inplace=True)\n",
        "\n",
        "df.head()\n",
        "\n",
        "df['ret_future'] = df.groupby('permno')['ret'].shift(-1)\n",
        "\n",
        "df = df.dropna()\n",
        "y = df['ret_future']\n",
        "X = df.drop(columns=['ret','ret_future','Date','permno']).copy()\n",
        "\n",
        "train = ('1967-01-01' <= df['Date']) & (df['Date'] < '1997-01-01')\n",
        "vali = ('1997-01-01' <= df['Date']) & (df['Date'] < '2007-01-01')\n",
        "test = ('2007-01-01' <= df['Date']) & (df['Date'] < '2016-11-01')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhELgKKcv18w",
        "colab_type": "code",
        "outputId": "31d4d37c-af4f-4376-d636-8ff6de63eea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>permno</th>\n",
              "      <th>ret</th>\n",
              "      <th>ST_REV</th>\n",
              "      <th>SUV</th>\n",
              "      <th>r12_2</th>\n",
              "      <th>NOA</th>\n",
              "      <th>SGA2S</th>\n",
              "      <th>LME</th>\n",
              "      <th>RNA</th>\n",
              "      <th>LTurnover</th>\n",
              "      <th>Lev</th>\n",
              "      <th>Resid_Var</th>\n",
              "      <th>D12</th>\n",
              "      <th>E12</th>\n",
              "      <th>b/m</th>\n",
              "      <th>ntis</th>\n",
              "      <th>tbl</th>\n",
              "      <th>tms</th>\n",
              "      <th>dfy</th>\n",
              "      <th>svar</th>\n",
              "      <th>ret_future</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1967-01-01</td>\n",
              "      <td>10006</td>\n",
              "      <td>0.136223</td>\n",
              "      <td>-0.241259</td>\n",
              "      <td>-0.325175</td>\n",
              "      <td>-0.043124</td>\n",
              "      <td>0.134033</td>\n",
              "      <td>-0.383450</td>\n",
              "      <td>0.010490</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.059441</td>\n",
              "      <td>-0.010490</td>\n",
              "      <td>-0.224942</td>\n",
              "      <td>2.880000</td>\n",
              "      <td>5.51667</td>\n",
              "      <td>0.533363</td>\n",
              "      <td>0.015698</td>\n",
              "      <td>0.0496</td>\n",
              "      <td>-0.0048</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.000733</td>\n",
              "      <td>-0.039703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>1967-02-01</td>\n",
              "      <td>10006</td>\n",
              "      <td>-0.039703</td>\n",
              "      <td>0.071096</td>\n",
              "      <td>-0.374126</td>\n",
              "      <td>-0.199301</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>-0.383450</td>\n",
              "      <td>0.019814</td>\n",
              "      <td>0.040793</td>\n",
              "      <td>-0.008159</td>\n",
              "      <td>-0.012821</td>\n",
              "      <td>-0.264569</td>\n",
              "      <td>2.890000</td>\n",
              "      <td>5.48333</td>\n",
              "      <td>0.540048</td>\n",
              "      <td>0.017701</td>\n",
              "      <td>0.0472</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.152727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>1967-03-01</td>\n",
              "      <td>10006</td>\n",
              "      <td>0.152727</td>\n",
              "      <td>-0.269767</td>\n",
              "      <td>0.179070</td>\n",
              "      <td>-0.155814</td>\n",
              "      <td>0.137209</td>\n",
              "      <td>-0.383721</td>\n",
              "      <td>0.004651</td>\n",
              "      <td>0.039535</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>-0.011628</td>\n",
              "      <td>-0.248837</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>5.45000</td>\n",
              "      <td>0.549551</td>\n",
              "      <td>0.014922</td>\n",
              "      <td>0.0456</td>\n",
              "      <td>-0.0001</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.000501</td>\n",
              "      <td>0.048883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1291</th>\n",
              "      <td>1967-04-01</td>\n",
              "      <td>10006</td>\n",
              "      <td>0.048883</td>\n",
              "      <td>0.389655</td>\n",
              "      <td>0.428736</td>\n",
              "      <td>-0.182759</td>\n",
              "      <td>0.134483</td>\n",
              "      <td>-0.385057</td>\n",
              "      <td>0.031034</td>\n",
              "      <td>0.042529</td>\n",
              "      <td>0.214943</td>\n",
              "      <td>-0.010345</td>\n",
              "      <td>0.067816</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>5.41000</td>\n",
              "      <td>0.530517</td>\n",
              "      <td>0.015046</td>\n",
              "      <td>0.0426</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.000837</td>\n",
              "      <td>-0.022112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1727</th>\n",
              "      <td>1967-05-01</td>\n",
              "      <td>10006</td>\n",
              "      <td>-0.022112</td>\n",
              "      <td>0.101382</td>\n",
              "      <td>-0.029954</td>\n",
              "      <td>0.050691</td>\n",
              "      <td>0.133641</td>\n",
              "      <td>-0.382489</td>\n",
              "      <td>0.034562</td>\n",
              "      <td>0.039171</td>\n",
              "      <td>0.013825</td>\n",
              "      <td>-0.006912</td>\n",
              "      <td>0.101382</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>5.37000</td>\n",
              "      <td>0.558201</td>\n",
              "      <td>0.011465</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>0.058524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194906</th>\n",
              "      <td>2015-12-01</td>\n",
              "      <td>93433</td>\n",
              "      <td>-0.264806</td>\n",
              "      <td>0.410389</td>\n",
              "      <td>0.485229</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.465534</td>\n",
              "      <td>0.475382</td>\n",
              "      <td>-0.352289</td>\n",
              "      <td>-0.477351</td>\n",
              "      <td>0.498523</td>\n",
              "      <td>-0.337518</td>\n",
              "      <td>0.499015</td>\n",
              "      <td>43.387887</td>\n",
              "      <td>86.53000</td>\n",
              "      <td>0.313649</td>\n",
              "      <td>-0.021620</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0256</td>\n",
              "      <td>0.0149</td>\n",
              "      <td>0.002839</td>\n",
              "      <td>-0.268100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196929</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>93433</td>\n",
              "      <td>-0.268100</td>\n",
              "      <td>-0.453511</td>\n",
              "      <td>-0.096439</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.465381</td>\n",
              "      <td>0.476756</td>\n",
              "      <td>-0.380317</td>\n",
              "      <td>-0.477745</td>\n",
              "      <td>0.491098</td>\n",
              "      <td>-0.337290</td>\n",
              "      <td>0.499011</td>\n",
              "      <td>43.550571</td>\n",
              "      <td>86.50000</td>\n",
              "      <td>0.331911</td>\n",
              "      <td>-0.020272</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0213</td>\n",
              "      <td>0.0145</td>\n",
              "      <td>0.004301</td>\n",
              "      <td>0.162368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198942</th>\n",
              "      <td>2016-02-01</td>\n",
              "      <td>93433</td>\n",
              "      <td>0.162368</td>\n",
              "      <td>-0.448310</td>\n",
              "      <td>-0.336481</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.465706</td>\n",
              "      <td>0.477137</td>\n",
              "      <td>-0.396123</td>\n",
              "      <td>-0.477634</td>\n",
              "      <td>0.302187</td>\n",
              "      <td>-0.339463</td>\n",
              "      <td>0.419483</td>\n",
              "      <td>43.713256</td>\n",
              "      <td>86.47000</td>\n",
              "      <td>0.330902</td>\n",
              "      <td>-0.024034</td>\n",
              "      <td>0.0026</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.002602</td>\n",
              "      <td>-0.074231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1200946</th>\n",
              "      <td>2016-03-01</td>\n",
              "      <td>93433</td>\n",
              "      <td>-0.074231</td>\n",
              "      <td>0.388667</td>\n",
              "      <td>0.263355</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.465552</td>\n",
              "      <td>0.476535</td>\n",
              "      <td>-0.382676</td>\n",
              "      <td>-0.477534</td>\n",
              "      <td>0.490514</td>\n",
              "      <td>-0.338742</td>\n",
              "      <td>0.351722</td>\n",
              "      <td>43.875940</td>\n",
              "      <td>86.44000</td>\n",
              "      <td>0.327955</td>\n",
              "      <td>-0.023008</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0131</td>\n",
              "      <td>0.001274</td>\n",
              "      <td>-0.101623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1202934</th>\n",
              "      <td>2016-04-01</td>\n",
              "      <td>93433</td>\n",
              "      <td>-0.101623</td>\n",
              "      <td>-0.429039</td>\n",
              "      <td>0.124056</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.465274</td>\n",
              "      <td>0.476346</td>\n",
              "      <td>-0.400352</td>\n",
              "      <td>-0.477353</td>\n",
              "      <td>0.398339</td>\n",
              "      <td>-0.338450</td>\n",
              "      <td>0.335430</td>\n",
              "      <td>44.070586</td>\n",
              "      <td>86.60000</td>\n",
              "      <td>0.326321</td>\n",
              "      <td>-0.023563</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0194</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0.000818</td>\n",
              "      <td>-0.053772</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1199669 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Date  permno       ret  ...     dfy      svar  ret_future\n",
              "0        1967-01-01   10006  0.136223  ...  0.0077  0.000733   -0.039703\n",
              "430      1967-02-01   10006 -0.039703  ...  0.0079  0.000412    0.152727\n",
              "860      1967-03-01   10006  0.152727  ...  0.0072  0.000501    0.048883\n",
              "1291     1967-04-01   10006  0.048883  ...  0.0072  0.000837   -0.022112\n",
              "1727     1967-05-01   10006 -0.022112  ...  0.0072  0.000890    0.058524\n",
              "...             ...     ...       ...  ...     ...       ...         ...\n",
              "1194906  2015-12-01   93433 -0.264806  ...  0.0149  0.002839   -0.268100\n",
              "1196929  2016-01-01   93433 -0.268100  ...  0.0145  0.004301    0.162368\n",
              "1198942  2016-02-01   93433  0.162368  ...  0.0138  0.002602   -0.074231\n",
              "1200946  2016-03-01   93433 -0.074231  ...  0.0131  0.001274   -0.101623\n",
              "1202934  2016-04-01   93433 -0.101623  ...  0.0117  0.000818   -0.053772\n",
              "\n",
              "[1199669 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yJeeZgHvdCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##########################################\n",
        "#normalized\n",
        "\n",
        "X -= X.loc[train].mean()\n",
        "X /= X.loc[train].std()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH5n7S70vdIl",
        "colab_type": "code",
        "outputId": "0fdbf14d-45af-4646-96b8-29cb9f54d8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "\n",
        "##########################################\n",
        "#train\n",
        "X[train],y[train]\n",
        "#vali\n",
        "X[vali],y[vali]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(          ST_REV       SUV     r12_2  ...       tms       dfy      svar\n",
              " 622823 -1.268085 -0.964422 -0.828734  ...  0.015681 -0.995991 -0.080044\n",
              " 625483 -1.568396  0.081883 -1.196952  ... -0.031046 -1.089615 -0.052961\n",
              " 628151  0.927439 -0.732485 -1.409699  ...  0.175890 -1.089615  0.071436\n",
              " 630825  1.330903  0.095651 -1.340994  ... -0.031046 -1.136427  0.308451\n",
              " 633526  0.104975 -1.026207 -1.025013  ... -0.071098 -1.113021  0.072838\n",
              " ...          ...       ...       ...  ...       ...       ...       ...\n",
              " 710284  0.933927 -0.418274 -0.083262  ... -0.011020 -0.808741  0.243462\n",
              " 713005  0.215012  0.161204 -0.382253  ... -0.144527 -0.668304  0.237573\n",
              " 715719 -1.290098  1.416624 -0.261127  ... -0.084449 -0.621492  0.750299\n",
              " 718422 -0.172253 -0.758604 -0.047144  ... -0.131177 -0.715117 -0.081420\n",
              " 721118  1.186107  0.096470 -0.172770  ... -0.137852 -1.066209 -0.129951\n",
              " \n",
              " [320245 rows x 18 columns], 622823    0.043719\n",
              " 625483    0.071458\n",
              " 628151   -0.004300\n",
              " 630825    0.248621\n",
              " 633526    0.030008\n",
              "             ...   \n",
              " 710284   -0.171783\n",
              " 713005   -0.038988\n",
              " 715719    0.232764\n",
              " 718422    0.510306\n",
              " 721118    0.170657\n",
              " Name: ret_future, Length: 320245, dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tohnnn5Uvg2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#build netural networking\n",
        "#32 16 8 \n",
        "def train_lr32(X, y, l_r):\n",
        "    \n",
        "    lamda = 0 # we don't regulariziation firstly\n",
        "    p = 0.1\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, activation='relu',\n",
        "                    kernel_regularizer=l2(l=lamda), \n",
        "                    kernel_initializer=he_normal(),\n",
        "                    input_dim=18))\n",
        "    model.add(Dropout(p))\n",
        "    model.add(Dense(16, activation='relu',\n",
        "                    kernel_regularizer=l2(l=lamda),\n",
        "                    kernel_initializer=he_normal()))\n",
        "    model.add(Dropout(p))\n",
        "    model.add(Dense(8, activation='relu',\n",
        "                    kernel_regularizer=l2(l=lamda),\n",
        "                    kernel_initializer=he_normal()))\n",
        "    model.add(Dropout(p))\n",
        "    model.add(Dense(1, activation='linear',\n",
        "                    kernel_initializer=he_normal()))\n",
        "    \n",
        "    model.compile(loss='mse',\n",
        "                  optimizer=Adam(lr=l_r, beta_1=0.9, beta_2=0.999),\n",
        "                  metrics=['mse'])\n",
        "    \n",
        "    \n",
        "    history = model.fit(X,y,epochs=20, batch_size=64,verbose=1)\n",
        "    \n",
        "    return model, history\n",
        "\n",
        "#18 18 18 18\n",
        "def train_lr_18ex(X, y, l_r):\n",
        "    lamda = 0 # we don't regulariziation firstly\n",
        "    p = 0.1\n",
        "    model = Sequential()\n",
        "    model.add(Dense(18, activation='relu',\n",
        "                    kernel_regularizer=l2(l=lamda), \n",
        "                    kernel_initializer=he_normal(),\n",
        "                    input_dim=18))\n",
        "    model.add(Dropout(p))\n",
        "    model.add(Dense(18, activation='relu',\n",
        "                    kernel_regularizer=l2(l=lamda),\n",
        "                    kernel_initializer=he_normal()))\n",
        "    model.add(Dropout(p))\n",
        "    model.add(Dense(18, activation='relu',\n",
        "                    kernel_regularizer=l2(l=lamda),\n",
        "                    kernel_initializer=he_normal()))\n",
        "    model.add(Dropout(p))\n",
        "    model.add(Dense(18, activation='relu',\n",
        "                    kernel_regularizer=l2(l=lamda),\n",
        "                    kernel_initializer=he_normal()))\n",
        "    model.add(Dropout(p))\n",
        "    model.add(Dense(1, activation='linear',\n",
        "                    kernel_initializer=he_normal()))\n",
        "    \n",
        "    model.compile(loss='mse',\n",
        "                  optimizer=Adam(lr=l_r, beta_1=0.9, beta_2=0.999),\n",
        "                  metrics=['mse'])\n",
        "    \n",
        "    \n",
        "    history = model.fit(X,y,epochs=20, batch_size=64,verbose=1)\n",
        "    \n",
        "    return model, history\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY2XntFXvjAn",
        "colab_type": "code",
        "outputId": "4ea3cdb4-b993-4807-9b23-be405295eb83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "\n",
        "train_X = X[train]\n",
        "train_y = y[train]    \n",
        "l_r_list = [0.001,0.005,0.01,0.05]\n",
        "loss=[0,0,0,0]\n",
        "metrics=[0,0,0,0]\n",
        "\n",
        "#different learning rate in 32 model\n",
        "model1, history1 = train_lr32(train_X, train_y, 0.001)\n",
        "model2, history2 = train_lr32(train_X, train_y, 0.005)\n",
        "model3, history3 = train_lr32(train_X, train_y, 0.01)\n",
        "model4, history4 = train_lr32(train_X, train_y, 0.05)\n",
        "#plot\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0374 - mse: 0.0374\n",
            "Epoch 2/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 3/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 4/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 5/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 6/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 7/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 8/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 9/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 10/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 11/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 12/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 13/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 14/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 15/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 16/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 17/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 18/20\n",
            "9635/9635 [==============================] - 15s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 19/20\n",
            "9635/9635 [==============================] - 16s 2ms/step - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 20/20\n",
            "5300/9635 [===============>..............] - ETA: 6s - loss: 0.0215 - mse: 0.0215"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsLZyC1ivlok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y0_001, = plt.plot(history1.history['loss'],label = '$0.001$')\n",
        "y0_005, = plt.plot(history2.history['loss'],label = '$0.005$')\n",
        "y0_01,  = plt.plot(history3.history['loss'],label = '$0.01$')\n",
        "y0_05,  = plt.plot(history4.history['loss'],label = '$0.05$')\n",
        "plt.legend(handles=[y0_001,y0_005, y0_01, y0_05]) \n",
        "#18*4 model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdKtyB24voDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model14, history14 = train_lr_18ex(train_X, train_y, 0.001)\n",
        "history14.history['loss']\n",
        "#compare\n",
        "history1.history['loss']\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}